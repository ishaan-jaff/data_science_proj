{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "At present there are approximately 7.7 billion people in the world with at least 3.5 billion of us online, implying that social media platforms are used by approximately one-in-three people in the world. This sudden growth and adoption has transformed the way we find partners, access news and information, or even how we organize political change and in so many other different ways. Leveraging the power of social media is now more important than ever before. This project aims to optimize social media activity for our users by providing them suggestions based on the analysis of data that we get from the Twitter API. Specifically,our project will have four key features that will provide suggestions on the following: \n",
    "    1. What the best time to post on social media would be \n",
    "    2. What are some keywords to include in a tweet based on post category and trending tweets \n",
    "    3. What are some hashtags to include in a tweet based on post category and trending tweets \n",
    "    4. What is the sentiment of the tweet the user has drafted\n",
    "For this project, we will be focusing specifically on Twitter. We have developed these four features because these are the four main components of a tweet that a user should think about before posting it. We want to ensure that a user is posting their tweet when the most people are going to see it. Additionally, we want to provide the user with suggestions of content, including the words itself and the hashtags, that has shown to be popular. Finally, we also want to ensure that the content that the user inputted is reflecting the same sentiment that they are intending to express."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Architecture Diagram](#Architecture-Diagram)\n",
    "- [Installing the Libraries](#Installing-the-Libraries)\n",
    "- [User Input](#User-Input)\n",
    "- [Gathering the Data](#Gathering-the-Data)\n",
    "    - [Data Cleaning and Preprocessing](#Data-Cleaning-and-Preprocessing)\n",
    "    - [Webscraping](#Webscraping)\n",
    "    - [Twitter API](#Twitter-API)\n",
    "- [Finding the Best Time to Post](#Finding-the-Best-Time-to-Post)\n",
    "- [Predicting Popular Keywords](#Predicting-Popular-Keywords)\n",
    "- [Predicting Hashtags](#Predicting-Hashtags)\n",
    "- [Sentiment Analysis](#Sentiment-Analysis)\n",
    "- [Future Research and Study](#Future-Research-and-Study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Diagram\n",
    "\n",
    "Below we have illustrated the pipeline that the data will follow. With our project, we will have the user input their username, the tweet that they intend on posting, and the category or categories of the tweet that the content of their tweet falls under. With this data, we can use the Twitter API to begin building a database of all the tweets that were posted globally that fall under the category that the user inputed. We also use webscraping to build a database of all of the tweets and posts on the users timeline. With this data, we can do a time series analysis to analyze the best time for social media engagment globally for the inputted category, as well as specifically for the user. Additionally, after we have cleaned and processed the data, we can use TFIDF to analyze the most popular keywords and hashtags for all tweets globally within the given category, as well as for all of the tweets of the user. Finally, we can use a sentiment analysis model to analyze the sentiment behind the tweet that the user intends on posting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Capture.png\" align = \"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the Libraries\n",
    "\n",
    "In order to gather the data, we will mainly be using Tweepy and the Twitter API, as well as, Selenium for webscraping. For each component of our project, we will be using different module for each component. For the time component, we will mainly be using Pandas for the time series analysis. For the keywords and hashtags, we will mainly be using the sklearn module. Finally, for the sentiment analysis, we will be using the Textblob and NLTK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import io\n",
    "import time\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from textblob import TextBlob\n",
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Input\n",
    "\n",
    "We will have the user input their username or Twitter handle to us for webscraping. We will also have the user input the tweet that they intend on posting for sentiment analysis. Finally, we will have the user input the category of their tweet in order to gather data on tweets that are more relevant to the tweet that the user wants to post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your username? elonmusk\n"
     ]
    }
   ],
   "source": [
    "user_name = input(\"What is your username? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is your tweet? Huge thanks to everyone who contributed ideas to Cybertruck. It’s better because of you! ♥️♥️♥️ #Tesla #Tech2020 #Design\n"
     ]
    }
   ],
   "source": [
    "orig_tweet = input(\"What is your tweet? \")\n",
    "#\"Huge thanks to everyone who contributed ideas to Cybertruck. It’s better because of you! ♥️♥️♥️ #Tesla #Tech2020 #Design\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the category of your tweet? These are the possible categories: Sports, Politics, Entertainment, Education, Technology, Business. Please input the categories comma separated. Business, Technology\n"
     ]
    }
   ],
   "source": [
    "#Possible Categories are: Sports\", \"Politics\", \"Entertainment\", \"Education\", \"Technology\", \"Business\"\n",
    "orig_categories = input(\"What is the category of your tweet? These are the possible categories: Sports, Politics, Entertainment, Education, Technology, Business. Please input the categories comma separated. \")\n",
    "orig_categories = orig_categories.split(\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Gathering the Data\n",
    "\n",
    "To begin with, we need to gather our data from Twitter. We will be using the Twitter API to get all of the tweets that were posted globally in the specfic inputted category. Then, we will be using webscraping to scrape the all of the posts from the user's timeline. However, in order to use the data that we have gathered, we need to clean and preprocess the data so that we can complete our analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing\n",
    "\n",
    "Below, we have listed out all of the functions that we will need to use in our project in order to process and analyze our data. In order to analyze the content of the user's intended tweet, the content of global tweets, and the content of the tweets on the user's timeline, we will need to replace all characters in each tweet that are not UTF-8 with a description of the emoji, remove all all of the extremely common words, or the stopwords, and break down the tweet into tokens of it's keywords and it's hashtags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet without emojis: Huge thanks to everyone who contributed ideas to Cybertruck. It's better because of you!  #Tesla #Tech2020 #Design\n",
      "\n",
      "Description of Emojis Used: BLACK HEART SUIT,VARIATION SELECTOR-16,BLACK HEART SUIT,VARIATION SELECTOR-16,BLACK HEART SUIT,VARIATION SELECTOR-16\n"
     ]
    }
   ],
   "source": [
    "### replace emojis with descriptions of the emojis \n",
    "def de_emoji(tweet):\n",
    "    new_tweet = \"\"\n",
    "    emojis = []\n",
    "    for character in tweet:\n",
    "        try:\n",
    "            character.encode(\"ascii\")\n",
    "            new_tweet += character\n",
    "        except UnicodeEncodeError:\n",
    "            replaced = unidecode(str(character))\n",
    "            if replaced != '' and replaced !=\"[?]\":\n",
    "                new_tweet += replaced\n",
    "            else:\n",
    "                try:\n",
    "                    emojis.append(unicodedata.name(character))\n",
    "                except ValueError:\n",
    "                     new_tweet += \"[x]\"\n",
    "    return new_tweet, \",\".join(emojis)\n",
    "orig_tweet, orig_emojis = de_emoji(orig_tweet)\n",
    "print(\"Tweet without emojis: \"+orig_tweet+\"\\n\")\n",
    "print(\"Description of Emojis Used: \"+orig_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['huge', 'thanks', 'everyone', 'contributed', 'idea', 'cybertruck', 'better', 'tesla', 'tech2020', 'design'] ['#tesla', '#tech2020', '#design'] []\n"
     ]
    }
   ],
   "source": [
    "lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "def preprocess(tweet):\n",
    "    \n",
    "    ## lowercase\n",
    "    lower_case = tweet.lower()\n",
    "    lower_case= re.sub(\"'s\", \"\", lower_case)\n",
    "    \n",
    "    ## removing apostrophes\n",
    "    lower_case = lower_case.translate(str.maketrans('', '', \"'\"))\n",
    "    lower_case = lower_case.translate(str.maketrans('', '', '\"'))\n",
    "    \n",
    "    ## removing punctuation, only considering alphanumeric characters\n",
    "    tweet_list = re.split('[^a-zA-Z0-9]', lower_case)\n",
    "    \n",
    "    str_list = [x for x in tweet_list if x != '']\n",
    "    \n",
    "    ## lemmatizing each word\n",
    "    str_list = [lemmatizer.lemmatize(x) for x in str_list]\n",
    "    \n",
    "    ## removing stopwords\n",
    "    str_list = [x for x in str_list if x not in stopwords.words('english')]\n",
    "    \n",
    "    hashtags, mentions = [], []\n",
    "    ## Creating a seperate lists for tweet texts, hashtags(#twitter), mentions(@elonmusk, @carnegiemellon)\n",
    "    for word in lower_case.split():\n",
    "        word = word.strip()\n",
    "        if len(word)>0 and word[0]==\"@\":\n",
    "            mentions.append(word)\n",
    "        if len(word)>0 and word[0]==\"#\":\n",
    "            hashtags.append(word)\n",
    "    return str_list, hashtags, mentions\n",
    "clean_tweet, hashtags, mentions = preprocess(orig_tweet)\n",
    "print(clean_tweet, hashtags, mentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Data\n",
    "\n",
    "Before we complete any of our analyses, we will be using all of the functions in our `clean_tweets` function to break down the content of our tweets into it's different components that we can analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Clean all tweets \n",
    "def clean_tweets(df):\n",
    "    clean_tweet, hashtags, mentions, emojis = [], [], [], []\n",
    "    for tweet in df['text']:\n",
    "        tweet, emoji = de_emoji(tweet)\n",
    "        tweet, hashtag, mention = preprocess(tweet)\n",
    "        clean_tweet.append(tweet)\n",
    "        hashtags.append(hashtag)\n",
    "        mentions.append(mention)\n",
    "        emojis.append(emoji)\n",
    "    df['text'] = clean_tweet\n",
    "    df['hashtags'] = hashtags\n",
    "    df['mentions'] = mentions\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reformatting the Data\n",
    "\n",
    "We will be using this function to reformat the time data that we are gathering from the webscraping to a DateTimeIndex format for our time series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert24(str1): \n",
    "    # Checking if last two elements of time \n",
    "    # is AM and first two elements are 12 \n",
    "    if str1[-2:] == \"AM\" and str1[:2] == \"12\": \n",
    "        return \"00\" + str1[2:-2]     \n",
    "    # remove the AM     \n",
    "    elif str1[-2:] == \"AM\": \n",
    "        return str1[:-2] \n",
    "    elif str1[-2:] == \"PM\" and str1[:2] == \"12\": \n",
    "        return str1[:-2] \n",
    "    else: \n",
    "        # add 12 to hours and remove PM \n",
    "        return str(int(str1[:2]) + 12) + str1[2:6] \n",
    "convert24('03:01 PM')\n",
    "\n",
    "def convertMonth(month):\n",
    "    m = {\n",
    "        'Jan': 1,\n",
    "        'Feb': 2,\n",
    "        'Mar': 3,\n",
    "        'Apr':4,\n",
    "         'May':5,\n",
    "         'Jun':6,\n",
    "         'Jul':7,\n",
    "         'Aug':8,\n",
    "         'Sep':9,\n",
    "         'Oct':10,\n",
    "         'Nov':11,\n",
    "         'Dec':12\n",
    "        }\n",
    "    return m[month]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             created_at                                               text  \\\n",
      "0   2019-12-10 15:01:00  #Saints DE Marcus Davenport suffered a signifi...   \n",
      "1   2019-12-10 15:00:00  All the best touchdowns from an AMAZING Week 1...   \n",
      "2   2019-12-10 14:26:00  RT to cast a #ProBowlVote for our Bucks\\n@Cant...   \n",
      "3   2019-12-10 14:30:00  These five rookies balled out in Week 14!  (vi...   \n",
      "4   2019-12-10 14:00:00  Source: #Redskins RB Derrius Guice is going on...   \n",
      "5   2019-12-10 14:00:00  The @Vikings defense was DOMINANT in Week 14. ...   \n",
      "6   2019-12-09 18:00:00  The Walmart in Fort Pierce, Fla., revealed Bea...   \n",
      "7   2019-12-10 12:47:00   Time to support your Tigers in the @NFL \\n RT...   \n",
      "8   2019-12-10 13:05:00  Eagles WR Alshon Jeffery (foot) to miss rest o...   \n",
      "9   2019-12-10 13:00:00  2019 Passing Yards Leaders through Week 14! \\n...   \n",
      "10  2019-12-10 12:45:00  Lamar Jackson (quad) on the field at #Ravens w...   \n",
      "11  2019-12-10 12:39:00  The 15 HIGHEST-GRADED players from Week 14!  (...   \n",
      "12  2019-12-10 12:12:00  1 RT = 1 Vote \\n\\nRT TO VOTE & TO SUPPORT YOUR...   \n",
      "13  2019-12-10 12:05:00  This Week in #NFL100 : Week 15\\nhttps://bit.ly...   \n",
      "14  2019-12-10 12:09:00  He really made two defenders hug each other......   \n",
      "15  2019-12-10 12:00:00  The postseason is three weeks away.\\n\\nIs YOUR...   \n",
      "16  2019-12-10 11:00:00  Congrats on making it this far.\\n\\nNow grab on...   \n",
      "17  2019-12-10 09:32:00  1 RT = 1 vote\\n\\n#ProBowlVote + @dak\\n#ProBowl...   \n",
      "18  2019-12-10 10:00:00  .@Showtyme_33 had another HUGE game in Week 14...   \n",
      "19  2019-12-10 09:50:00  \"You know how much composure it takes to make ...   \n",
      "\n",
      "   emojis  favorite_count  retweet_count  \n",
      "0                   329.0          158.0  \n",
      "1                   342.0           61.0  \n",
      "2                   760.0          746.0  \n",
      "3                   320.0           39.0  \n",
      "4                   973.0          199.0  \n",
      "5                   303.0           43.0  \n",
      "6                     0.0            0.0  \n",
      "7                   467.0          350.0  \n",
      "8                   940.0          213.0  \n",
      "9                   794.0          133.0  \n",
      "10                  253.0           40.0  \n",
      "11                  477.0           77.0  \n",
      "12                  393.0          505.0  \n",
      "13                   54.0           14.0  \n",
      "14                    0.0            0.0  \n",
      "15                    0.0          349.0  \n",
      "16                  197.0           17.0  \n",
      "17                  487.0          781.0  \n",
      "18                  886.0          103.0  \n",
      "19                  914.0          127.0  \n"
     ]
    }
   ],
   "source": [
    "def format_date(user_timeline_df):\n",
    "    user_timeline_df['created_at'] = user_timeline_df['created_at'].astype(str)\n",
    "    for index,row in user_timeline_df.iterrows():\n",
    "        #print(row['created_at'])\n",
    "        dash_index = row['created_at'].find(\"-\")\n",
    "        if \":\" in row['created_at'][:2]:\n",
    "            time = '0' + row['created_at'][:dash_index-1]\n",
    "        else:\n",
    "            time = row['created_at'][:dash_index-1]\n",
    "        time = convert24(time)[:-1] + ':00'\n",
    "        #print(row['created_at'][index+2:])\n",
    "        year = row['created_at'][dash_index+2:][-4:] + \"-\"\n",
    "        #print(row['created_at'][dash_index+2:][-8:-5])\n",
    "        month = str(convertMonth(row['created_at'][dash_index+2:][-8:-5])) + '-'\n",
    "        if \" \" in row['created_at'][dash_index+2:][:2]:\n",
    "            day = \"0\" + row['created_at'][dash_index+2:][0]\n",
    "        else:\n",
    "            day = row['created_at'][dash_index+2:][:2]\n",
    "        date = year + month + day\n",
    "        user_timeline_df[index:]['created_at'] = date + \" \" + time\n",
    "    return user_timeline_df\n",
    "    \n",
    "#user_timeline_df = format_date(user_timeline_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Webscraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping the user's timelines\n",
    "def scraped_timeline(content, page, seen_tweets):\n",
    "    soup = BeautifulSoup(page, \"html.parser\")\n",
    "    timeline = soup.select('#timeline li.stream-item')\n",
    "    for i, tweet in enumerate(timeline):\n",
    "        count = tweet.select('span.ProfileTweet-actionCount')\n",
    "        favs = 0.0\n",
    "        retweets = 0.0\n",
    "        for j in range(1, 3):  \n",
    "            elem = count[j]\n",
    "            val = elem.get_text().strip()\n",
    "            num = \"\"\n",
    "            i = 0\n",
    "            while (i<len(val) and not(val[i]== \" \" or val[i]==\"\")):\n",
    "                num+=val[i]\n",
    "                i+=1\n",
    "            if num!=\"\":\n",
    "                num = num.replace(',' , '')\n",
    "                if num.isdigit():\n",
    "                    if j==1:\n",
    "                        retweets = int(num)\n",
    "                    elif j==2:\n",
    "                        favs = int(num)\n",
    "        tweet_text = tweet.select('p.tweet-text')[0].get_text()\n",
    "        tweet_time = tweet.select('a.tweet-timestamp')\n",
    "        for elem in tweet_time:\n",
    "            time = (elem.get('title'))   \n",
    "        if tweet_text not in seen_tweets:\n",
    "            seen_tweets.add(tweet.text)\n",
    "            text, emojis = deEmojify(tweet_text)\n",
    "            content[\"created_at\"].append(time)\n",
    "            content[\"text\"].append(text)\n",
    "            content[\"emojis\"].append(emojis)\n",
    "            content[\"favorite_count\"].append(favs)\n",
    "            content[\"retweet_count\"].append(retweets)\n",
    "            \n",
    "    return    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_timeline_df(user_name, no_of_pagedowns=1):\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    browser = driver\n",
    "    url = \"https://twitter.com/\" + user_name\n",
    "    browser.get(url)\n",
    "    time.sleep(1)\n",
    "    elem = browser.find_element_by_tag_name(\"body\")\n",
    "    while no_of_pagedowns>=0:\n",
    "        elem.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(0.2)\n",
    "        no_of_pagedowns-=1\n",
    "\n",
    "    content = {\"created_at\":[], \"text\":[], \"emojis\":[], \"favorite_count\":[], \"retweet_count\":[]}\n",
    "    seen_tweets = set()\n",
    "    html_source = scraped_timeline(content, browser.page_source, seen_tweets)\n",
    "    user_timeline_df = pd.DataFrame.from_dict(content)\n",
    "    return user_timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to download new driver from http://chromedriver.storage.googleapis.com/78.0.3904.105/chromedriver_win32.zip\n",
      "Unpack archive C:\\Users\\User\\.wdm\\drivers\\chromedriver\\78.0.3904.105\\win32\\chromedriver.zip\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\User\\\\.wdm\\\\drivers\\\\chromedriver\\\\78.0.3904.105\\\\win32\\\\chromedriver.exe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-dec9a01f7805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muser_timeline_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_timeline_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mclean_tweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmentions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memojis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0muser_timeline_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0memoji\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mde_emoji\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-140-1c40b9044897>\u001b[0m in \u001b[0;36mcreate_timeline_df\u001b[1;34m(user_name, no_of_pagedowns)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_timeline_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mno_of_pagedowns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mChromeDriverManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mbrowser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://twitter.com/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0muser_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mbrowser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\chrome.py\u001b[0m in \u001b[0;36minstall\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minstall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdriver_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0o755\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\manager.py\u001b[0m in \u001b[0;36mdownload_driver\u001b[1;34m(self, driver)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__download_and_save_driver_to_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_latest\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\manager.py\u001b[0m in \u001b[0;36m__download_and_save_driver_to_cache\u001b[1;34m(self, driver, driver_version)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdownload_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         return self.driver_cache.save_driver_to_cache(response, driver.get_name(), driver_version,\n\u001b[1;32m---> 29\u001b[1;33m                                                       driver.get_os_type())\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdownload_driver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\driver_cache.py\u001b[0m in \u001b[0;36msave_driver_to_cache\u001b[1;34m(self, response, driver_name, version, os_type)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mwrite_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mfiles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__unpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\driver_cache.py\u001b[0m in \u001b[0;36m__unpack\u001b[1;34m(self, path, to_directory)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mto_directory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mextract_zip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0mfile_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract_tar_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\webdriver_manager\\archive.py\u001b[0m in \u001b[0;36mextract_zip\u001b[1;34m(zip_file, to_directory)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract_zip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0marchive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_directory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[1;34m(self, path, members, pwd)\u001b[0m\n\u001b[0;32m   1614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1615\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1616\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1618\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[1;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[0;32m   1668\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1669\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1670\u001b[1;33m              \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1671\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\User\\\\.wdm\\\\drivers\\\\chromedriver\\\\78.0.3904.105\\\\win32\\\\chromedriver.exe'"
     ]
    }
   ],
   "source": [
    "user_timeline_df = create_timeline_df(user_name)\n",
    "clean_tweet, hashtags, mentions, emojis = [], [], [], []\n",
    "for tweet in user_timeline_df['text']:\n",
    "    tweet, emoji = de_emoji(tweet)\n",
    "    tweet, hashtag, mention = preprocess(tweet)\n",
    "    clean_tweet.append(tweet)\n",
    "    hashtags.append(hashtag)\n",
    "    mentions.append(mention)\n",
    "    emojis.append(emoji)\n",
    "user_timeline_df['text'] = clean_tweet\n",
    "user_timeline_df['hashtags'] = hashtags\n",
    "user_timeline_df['mentions'] = mentions\n",
    "user_timeline_df['emojis'] = emojis\n",
    "user_timeline_df = format_date(user_timeline_df)\n",
    "user_timeline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "#from retrying import retry\n",
    "\n",
    "#@retry(wait_exponential_multiplier=1000, wait_exponential_max=10000)\n",
    "def get_tweets():\n",
    "    consumer_key = \"jKh08dfgDeTPztN1rzCpTG7Ub\"\n",
    "    consumer_secret = \"piCHq08QogdkccQjQ4w74ejfNZl0ZLJeN5QDfkyNKp1AUG1nL8\"\n",
    "    access_token = \"968209315285946373-kB1go0AZDLjgR3uw8D04fkekvLNGrM2\"\n",
    "    access_secret = \"49zXLZmjYPdVwIufciUGgM5vtn9YtLD4YehU6pydKCWZY\"\n",
    "    \n",
    "    try:\n",
    "        print(\"hello\")\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_secret)\n",
    "        api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "        csvFile = open('final-project-tweets.csv', 'a')\n",
    "\n",
    "        #Use csv writer\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        csvWriter.writerow([\"category\", \"screen_name\", \"created_at\", \"text\", \"emojis\", \"favorite_count\", \"retweet_count\", \"follower_count\"])\n",
    "        categories = [\"Sports\", \"Politics\", \"Entertainment\", \"Education\", \"Technology\", \"Business\"]\n",
    "        dates = [\"11-27\", \"11-28\", \"11-29\", \"11-30\", \"11-31\", \"12-1\", \"12-2\", \"12-3\", \"12-4\"]\n",
    "        for category in categories:\n",
    "            for date in range(len(dates)-1):\n",
    "                for tweet in tweepy.Cursor(api.search,q = category,since = \"2019-\"+dates[date],until = \"2019-\"+dates[date+1],lang = \"en\", result_type = 'popular').items():\n",
    "                    text, emojis = deEmojify(tweet.text)\n",
    "                    csvWriter.writerow([category, tweet.user.screen_name, tweet.created_at, text, emojis, tweet.favorite_count, tweet.retweet_count, tweet.user.followers_count])\n",
    "                    #print(category, tweet.user.screen_name, tweet.created_at, text, emojis, tweet.favorite_count, tweet.retweet_count, tweet.user.followers_count) #, tweet.get_tweet_sentiment(tweet.test))\n",
    "                    time.sleep(.200)\n",
    "                    #print (tweet.user.screen_name, tweet.created_at, tweet.text)\n",
    "        csvFile.close()\n",
    "    except tweepy.error.TweepError:\n",
    "        raise\n",
    "        \n",
    "get_tweets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>follower_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AlwaysLateESPN</td>\n",
       "      <td>2019-12-02 22:30:12</td>\n",
       "      <td>What are we doing this week to ruin sports for...</td>\n",
       "      <td>SMILING FACE WITH HORNS</td>\n",
       "      <td>68595</td>\n",
       "      <td>15994</td>\n",
       "      <td>30470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>DVATW</td>\n",
       "      <td>2019-12-02 20:13:55</td>\n",
       "      <td>Enthusiastic \"new Swede\" proves his sporting i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916</td>\n",
       "      <td>642</td>\n",
       "      <td>129758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>FCBarcelona</td>\n",
       "      <td>2019-12-02 22:41:05</td>\n",
       "      <td>[?][?] The sports world hails Leo #Messi #Ball...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14383</td>\n",
       "      <td>2244</td>\n",
       "      <td>31410733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports</td>\n",
       "      <td>faizanlakhani</td>\n",
       "      <td>2019-12-02 19:03:51</td>\n",
       "      <td>Few bad games in Cricket and everyone, from sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2087</td>\n",
       "      <td>342</td>\n",
       "      <td>181730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports</td>\n",
       "      <td>DanWetzel</td>\n",
       "      <td>2019-12-02 21:05:24</td>\n",
       "      <td>The repetitive relic that is \"Conference Champ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129</td>\n",
       "      <td>210</td>\n",
       "      <td>291320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category     screen_name           created_at  \\\n",
       "0   Sports  AlwaysLateESPN  2019-12-02 22:30:12   \n",
       "1   Sports           DVATW  2019-12-02 20:13:55   \n",
       "2   Sports     FCBarcelona  2019-12-02 22:41:05   \n",
       "3   Sports   faizanlakhani  2019-12-02 19:03:51   \n",
       "4   Sports       DanWetzel  2019-12-02 21:05:24   \n",
       "\n",
       "                                                text                   emojis  \\\n",
       "0  What are we doing this week to ruin sports for...  SMILING FACE WITH HORNS   \n",
       "1  Enthusiastic \"new Swede\" proves his sporting i...                      NaN   \n",
       "2  [?][?] The sports world hails Leo #Messi #Ball...                      NaN   \n",
       "3  Few bad games in Cricket and everyone, from sh...                      NaN   \n",
       "4  The repetitive relic that is \"Conference Champ...                      NaN   \n",
       "\n",
       "   favorite_count  retweet_count  follower_count  \n",
       "0           68595          15994           30470  \n",
       "1             916            642          129758  \n",
       "2           14383           2244        31410733  \n",
       "3            2087            342          181730  \n",
       "4            1129            210          291320  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"final-project-tweets.csv\") \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['created_at'] = pd.DatetimeIndex(data['created_at'])\n",
    "data['created_at'] = data['created_at'].dt.time.astype(str)\n",
    "data['created_at'] = pd.DatetimeIndex(data['created_at'])\n",
    "data['popularity'] = (data['favorite_count'] + data['retweet_count'])/data['follower_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>follower_count</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AlwaysLateESPN</td>\n",
       "      <td>2019-12-11 22:30:12</td>\n",
       "      <td>What are we doing this week to ruin sports for...</td>\n",
       "      <td>SMILING FACE WITH HORNS</td>\n",
       "      <td>68595</td>\n",
       "      <td>15994</td>\n",
       "      <td>30470</td>\n",
       "      <td>2.776140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sports</td>\n",
       "      <td>DVATW</td>\n",
       "      <td>2019-12-11 20:13:55</td>\n",
       "      <td>Enthusiastic \"new Swede\" proves his sporting i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>916</td>\n",
       "      <td>642</td>\n",
       "      <td>129758</td>\n",
       "      <td>0.012007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sports</td>\n",
       "      <td>FCBarcelona</td>\n",
       "      <td>2019-12-11 22:41:05</td>\n",
       "      <td>[?][?] The sports world hails Leo #Messi #Ball...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14383</td>\n",
       "      <td>2244</td>\n",
       "      <td>31410733</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sports</td>\n",
       "      <td>faizanlakhani</td>\n",
       "      <td>2019-12-11 19:03:51</td>\n",
       "      <td>Few bad games in Cricket and everyone, from sh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2087</td>\n",
       "      <td>342</td>\n",
       "      <td>181730</td>\n",
       "      <td>0.013366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sports</td>\n",
       "      <td>DanWetzel</td>\n",
       "      <td>2019-12-11 21:05:24</td>\n",
       "      <td>The repetitive relic that is \"Conference Champ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1129</td>\n",
       "      <td>210</td>\n",
       "      <td>291320</td>\n",
       "      <td>0.004596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sports</td>\n",
       "      <td>roaringriot</td>\n",
       "      <td>2019-12-11 17:46:56</td>\n",
       "      <td>We are still Panthers fans today, forever and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295</td>\n",
       "      <td>228</td>\n",
       "      <td>18932</td>\n",
       "      <td>0.027625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sports</td>\n",
       "      <td>SkyFootball</td>\n",
       "      <td>2019-12-11 21:38:56</td>\n",
       "      <td>Austin converts from the spot in the 90th minu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>970</td>\n",
       "      <td>114</td>\n",
       "      <td>352007</td>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 23:54:36</td>\n",
       "      <td>.@stefondiggs playing catch with fans pregame!...</td>\n",
       "      <td>AMERICAN FOOTBALL,TELEVISION,MOBILE PHONE</td>\n",
       "      <td>705</td>\n",
       "      <td>81</td>\n",
       "      <td>24818782</td>\n",
       "      <td>0.000032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 23:40:48</td>\n",
       "      <td>Canada's own @LWillson_82 loves that look, @TD...</td>\n",
       "      <td>FACE WITH TEARS OF JOY,REGIONAL INDICATOR SYMB...</td>\n",
       "      <td>668</td>\n",
       "      <td>85</td>\n",
       "      <td>24818782</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sports</td>\n",
       "      <td>chiproytx</td>\n",
       "      <td>2019-12-11 21:20:16</td>\n",
       "      <td>\"J.K. Dobbins' mom, Mya, became pregnant when ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>95</td>\n",
       "      <td>22615</td>\n",
       "      <td>0.014150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sports</td>\n",
       "      <td>darrenrovell</td>\n",
       "      <td>2019-12-11 22:46:49</td>\n",
       "      <td>Four players were suspended from the NFL for s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>170</td>\n",
       "      <td>51</td>\n",
       "      <td>2053828</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sports</td>\n",
       "      <td>OnionSports</td>\n",
       "      <td>2019-12-11 22:38:07</td>\n",
       "      <td>Dallas Cowboys Release Jerry Jones https://t.c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423</td>\n",
       "      <td>93</td>\n",
       "      <td>268621</td>\n",
       "      <td>0.001921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sports</td>\n",
       "      <td>RoyNemer</td>\n",
       "      <td>2019-12-11 22:49:49</td>\n",
       "      <td>Messi could have zero Ballon d'Ors and it woul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>486</td>\n",
       "      <td>100</td>\n",
       "      <td>21724</td>\n",
       "      <td>0.026975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sports</td>\n",
       "      <td>RoyNemer</td>\n",
       "      <td>2019-12-11 22:51:26</td>\n",
       "      <td>Imagine someone dominating in goals scored, as...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381</td>\n",
       "      <td>92</td>\n",
       "      <td>21724</td>\n",
       "      <td>0.021773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sports</td>\n",
       "      <td>AdamHBeasley</td>\n",
       "      <td>2019-12-11 21:50:39</td>\n",
       "      <td>A lot of people who talk and write about footb...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>609</td>\n",
       "      <td>95</td>\n",
       "      <td>45673</td>\n",
       "      <td>0.015414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sports</td>\n",
       "      <td>Ouachita</td>\n",
       "      <td>2019-12-11 17:30:11</td>\n",
       "      <td>If you've never made it to see the Battle of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118</td>\n",
       "      <td>47</td>\n",
       "      <td>7648</td>\n",
       "      <td>0.021574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sports</td>\n",
       "      <td>GeoffBakerTIMES</td>\n",
       "      <td>2019-12-11 17:24:31</td>\n",
       "      <td>Under fire for handling of player abuse allega...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48</td>\n",
       "      <td>28</td>\n",
       "      <td>25398</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sports</td>\n",
       "      <td>cmdabe</td>\n",
       "      <td>2019-12-11 17:42:07</td>\n",
       "      <td>.@ArchRUMMEL moves up another spot in latest U...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>2918</td>\n",
       "      <td>0.024332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sports</td>\n",
       "      <td>HoustonChronHS</td>\n",
       "      <td>2019-12-11 17:40:24</td>\n",
       "      <td>Morton Ranch's Brown, Paetow's Mourning, Katy'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55</td>\n",
       "      <td>15</td>\n",
       "      <td>14348</td>\n",
       "      <td>0.004879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sports</td>\n",
       "      <td>rameshlaus</td>\n",
       "      <td>2019-12-11 16:58:33</td>\n",
       "      <td>#YahooIndia Most Searched Sports Personality o...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11747</td>\n",
       "      <td>2568</td>\n",
       "      <td>433079</td>\n",
       "      <td>0.033054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 02:15:19</td>\n",
       "      <td>One of the craziest Pick-6s you'll ever see.\\r...</td>\n",
       "      <td>HOUSE BUILDING,COMBINING ENCLOSING KEYCAP,TELE...</td>\n",
       "      <td>2281</td>\n",
       "      <td>585</td>\n",
       "      <td>24818781</td>\n",
       "      <td>0.000115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sports</td>\n",
       "      <td>UKLabour</td>\n",
       "      <td>2019-12-11 16:30:00</td>\n",
       "      <td>These 5 employers have exploited, ripped off a...</td>\n",
       "      <td>PERSONAL COMPUTER,T-SHIRT,HOSPITAL,SHOPPING BA...</td>\n",
       "      <td>1292</td>\n",
       "      <td>703</td>\n",
       "      <td>792238</td>\n",
       "      <td>0.002518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sports</td>\n",
       "      <td>ArvindKejriwal</td>\n",
       "      <td>2019-12-11 12:14:59</td>\n",
       "      <td>We passed Bills in Del Assembly in last 2 days...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9462</td>\n",
       "      <td>1745</td>\n",
       "      <td>15957107</td>\n",
       "      <td>0.000702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sports</td>\n",
       "      <td>orangeandwhite</td>\n",
       "      <td>2019-12-11 18:51:30</td>\n",
       "      <td>Paul Finebaum called Dabo Swinney \"the most an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2061</td>\n",
       "      <td>310</td>\n",
       "      <td>39845</td>\n",
       "      <td>0.059506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sports</td>\n",
       "      <td>UberFacts</td>\n",
       "      <td>2019-12-11 00:47:01</td>\n",
       "      <td>In 1989, a couple from New York paid $100 for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3988</td>\n",
       "      <td>363</td>\n",
       "      <td>13979016</td>\n",
       "      <td>0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sports</td>\n",
       "      <td>GetUpESPN</td>\n",
       "      <td>2019-12-11 15:08:40</td>\n",
       "      <td>\"I think Dabo Swinney is the most annoying win...</td>\n",
       "      <td>FLUSHED FACE,FLUSHED FACE,FLUSHED FACE</td>\n",
       "      <td>6109</td>\n",
       "      <td>1198</td>\n",
       "      <td>73069</td>\n",
       "      <td>0.100001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 03:54:30</td>\n",
       "      <td>FAKE PUNT ALERT \\r\\n\\r\\nThe @Seahawks special...</td>\n",
       "      <td>POLICE CARS REVOLVING LIGHT,POLICE CARS REVOLV...</td>\n",
       "      <td>2567</td>\n",
       "      <td>490</td>\n",
       "      <td>24818781</td>\n",
       "      <td>0.000123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 03:31:54</td>\n",
       "      <td>WIDE OPEN.\\r\\n\\r\\n@DangeRussWilson to David Mo...</td>\n",
       "      <td>TELEVISION</td>\n",
       "      <td>1870</td>\n",
       "      <td>444</td>\n",
       "      <td>24818781</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sports</td>\n",
       "      <td>BABYMETAL_JAPAN</td>\n",
       "      <td>2019-12-11 04:02:22</td>\n",
       "      <td>METAL GALAXY WORLD TOUR (TAIPEI ) - Ticket Inf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2515</td>\n",
       "      <td>495</td>\n",
       "      <td>350224</td>\n",
       "      <td>0.008594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sports</td>\n",
       "      <td>NFL</td>\n",
       "      <td>2019-12-11 00:24:17</td>\n",
       "      <td>\"Time to be great.\" - @DangeRussWilson #Seahaw...</td>\n",
       "      <td>TELEVISION,MOBILE PHONE</td>\n",
       "      <td>3347</td>\n",
       "      <td>436</td>\n",
       "      <td>24818781</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Business</td>\n",
       "      <td>sekartweets</td>\n",
       "      <td>2019-12-11 14:06:12</td>\n",
       "      <td>#27YrsOfKwEmperorVIJAY - From facing brutal cr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5205</td>\n",
       "      <td>2624</td>\n",
       "      <td>122778</td>\n",
       "      <td>0.063765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>Business</td>\n",
       "      <td>mannyfidel</td>\n",
       "      <td>2019-12-11 18:40:28</td>\n",
       "      <td>I'm willing to raise the necessary funds for K...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14091</td>\n",
       "      <td>1890</td>\n",
       "      <td>8464</td>\n",
       "      <td>1.888114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Business</td>\n",
       "      <td>nytimes</td>\n",
       "      <td>2019-12-11 15:54:34</td>\n",
       "      <td>Breaking News: Deutsche Bank must turn over de...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9317</td>\n",
       "      <td>3913</td>\n",
       "      <td>44614211</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Business</td>\n",
       "      <td>paulmozur</td>\n",
       "      <td>2019-12-11 09:03:03</td>\n",
       "      <td>In Xinjiang, Chinese police are using the bloo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5621</td>\n",
       "      <td>5344</td>\n",
       "      <td>31485</td>\n",
       "      <td>0.348261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>Business</td>\n",
       "      <td>EpochTimes</td>\n",
       "      <td>2019-12-11 03:10:01</td>\n",
       "      <td>6 out of 10 small business owners approve of P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>760</td>\n",
       "      <td>585</td>\n",
       "      <td>165213</td>\n",
       "      <td>0.008141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Business</td>\n",
       "      <td>AnandWrites</td>\n",
       "      <td>2019-12-11 22:31:57</td>\n",
       "      <td>The moral meltdown of McKinsey is one of the m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1895</td>\n",
       "      <td>820</td>\n",
       "      <td>563991</td>\n",
       "      <td>0.004814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Business</td>\n",
       "      <td>cvpayne</td>\n",
       "      <td>2019-12-11 18:49:05</td>\n",
       "      <td>I'm in DC were I just wrapped an exclusive int...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6144</td>\n",
       "      <td>1487</td>\n",
       "      <td>415198</td>\n",
       "      <td>0.018379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>Business</td>\n",
       "      <td>HawleyMO</td>\n",
       "      <td>2019-12-11 21:11:04</td>\n",
       "      <td>#China using DNA to create facial images to tr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3233</td>\n",
       "      <td>2389</td>\n",
       "      <td>132243</td>\n",
       "      <td>0.042513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Business</td>\n",
       "      <td>RepJimBanks</td>\n",
       "      <td>2019-12-11 15:19:35</td>\n",
       "      <td>China using DNA samples to map Uighur faces as...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3288</td>\n",
       "      <td>3189</td>\n",
       "      <td>21642</td>\n",
       "      <td>0.299279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Business</td>\n",
       "      <td>BleacherReport</td>\n",
       "      <td>2019-12-11 04:28:55</td>\n",
       "      <td>.@DangeRussWilson leads the Seahawks past the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6581</td>\n",
       "      <td>889</td>\n",
       "      <td>7787569</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Business</td>\n",
       "      <td>Timodc</td>\n",
       "      <td>2019-12-11 03:51:59</td>\n",
       "      <td>So weird that America First isolationism alway...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2433</td>\n",
       "      <td>593</td>\n",
       "      <td>91111</td>\n",
       "      <td>0.033212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Business</td>\n",
       "      <td>jrhennessy</td>\n",
       "      <td>2019-12-11 22:13:35</td>\n",
       "      <td>the big consulting firms really do not suffer ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1797</td>\n",
       "      <td>566</td>\n",
       "      <td>28296</td>\n",
       "      <td>0.083510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Business</td>\n",
       "      <td>ashoswai</td>\n",
       "      <td>2019-12-11 07:21:38</td>\n",
       "      <td>#Kashmir is only place in the world, where reg...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>727</td>\n",
       "      <td>497</td>\n",
       "      <td>143069</td>\n",
       "      <td>0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Business</td>\n",
       "      <td>ABC</td>\n",
       "      <td>2019-12-11 04:54:05</td>\n",
       "      <td>China says it will suspend U.S. Navy visits to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2345</td>\n",
       "      <td>2205</td>\n",
       "      <td>14717857</td>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Business</td>\n",
       "      <td>EpochTimes</td>\n",
       "      <td>2019-12-11 00:25:00</td>\n",
       "      <td>6 out of 10 small business owners approve of P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001</td>\n",
       "      <td>412</td>\n",
       "      <td>165213</td>\n",
       "      <td>0.008553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Business</td>\n",
       "      <td>CREWcrew</td>\n",
       "      <td>2019-12-11 00:00:46</td>\n",
       "      <td>Donald Trump has now made an astounding 400 pr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>241</td>\n",
       "      <td>182</td>\n",
       "      <td>303543</td>\n",
       "      <td>0.001394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Business</td>\n",
       "      <td>GOP</td>\n",
       "      <td>2019-12-11 00:12:00</td>\n",
       "      <td>Promises MADE, promises KEPT!\\r\\n\\r\\nhttps://t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4692</td>\n",
       "      <td>1409</td>\n",
       "      <td>2129572</td>\n",
       "      <td>0.002865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Business</td>\n",
       "      <td>BillKristol</td>\n",
       "      <td>2019-12-11 00:57:10</td>\n",
       "      <td>\"Trump has long maintained that he did not hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>452</td>\n",
       "      <td>222</td>\n",
       "      <td>560365</td>\n",
       "      <td>0.001203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Business</td>\n",
       "      <td>WWE</td>\n",
       "      <td>2019-12-11 02:19:22</td>\n",
       "      <td>More business is about to be handled by @Andra...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1068</td>\n",
       "      <td>244</td>\n",
       "      <td>10754452</td>\n",
       "      <td>0.000122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>Business</td>\n",
       "      <td>prasannavishy</td>\n",
       "      <td>2019-12-11 00:10:26</td>\n",
       "      <td>The economics of Christian anti-Semitism - As ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>111</td>\n",
       "      <td>80</td>\n",
       "      <td>103026</td>\n",
       "      <td>0.001854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Business</td>\n",
       "      <td>WorldWideWob</td>\n",
       "      <td>2019-12-11 02:58:53</td>\n",
       "      <td>this is a tweet to inform you the Knicks score...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>812</td>\n",
       "      <td>64</td>\n",
       "      <td>468145</td>\n",
       "      <td>0.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Business</td>\n",
       "      <td>latimes</td>\n",
       "      <td>2019-12-11 01:48:00</td>\n",
       "      <td>Column: Buttigieg is wrong--Free college shoul...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>604</td>\n",
       "      <td>181</td>\n",
       "      <td>3464266</td>\n",
       "      <td>0.000227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Business</td>\n",
       "      <td>blakeshelton</td>\n",
       "      <td>2019-12-11 00:30:00</td>\n",
       "      <td>Had a blast taking care of business last week ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980</td>\n",
       "      <td>141</td>\n",
       "      <td>20587052</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>Business</td>\n",
       "      <td>PaulBegala</td>\n",
       "      <td>2019-12-11 00:12:51</td>\n",
       "      <td>In a business with too many narcissists, charl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>423</td>\n",
       "      <td>57</td>\n",
       "      <td>207339</td>\n",
       "      <td>0.002315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Business</td>\n",
       "      <td>business</td>\n",
       "      <td>2019-12-11 02:54:26</td>\n",
       "      <td>The U.S. is bracing for a possible French fry ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135</td>\n",
       "      <td>75</td>\n",
       "      <td>5739652</td>\n",
       "      <td>0.000037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Business</td>\n",
       "      <td>business</td>\n",
       "      <td>2019-12-11 02:38:21</td>\n",
       "      <td>China hints a U.S. blacklist of \"unreliable en...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>5739652</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Business</td>\n",
       "      <td>jaketapper</td>\n",
       "      <td>2019-12-11 02:03:41</td>\n",
       "      <td>LA Times: Jury orders billionaire Alki David t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>436</td>\n",
       "      <td>131</td>\n",
       "      <td>2203713</td>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Business</td>\n",
       "      <td>JonErlichman</td>\n",
       "      <td>2019-12-11 00:17:13</td>\n",
       "      <td>VC investments in space startups:\\r\\n \\r\\n2019...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>337</td>\n",
       "      <td>120</td>\n",
       "      <td>113548</td>\n",
       "      <td>0.004025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Business</td>\n",
       "      <td>RobertMaguire_</td>\n",
       "      <td>2019-12-11 00:56:46</td>\n",
       "      <td>The administration headed by a president who s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136</td>\n",
       "      <td>88</td>\n",
       "      <td>60249</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Business</td>\n",
       "      <td>foe_us</td>\n",
       "      <td>2019-12-11 00:00:04</td>\n",
       "      <td>Emails show that chemical giant @Bayer discuss...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>169687</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category      screen_name          created_at  \\\n",
       "0      Sports   AlwaysLateESPN 2019-12-11 22:30:12   \n",
       "1      Sports            DVATW 2019-12-11 20:13:55   \n",
       "2      Sports      FCBarcelona 2019-12-11 22:41:05   \n",
       "3      Sports    faizanlakhani 2019-12-11 19:03:51   \n",
       "4      Sports        DanWetzel 2019-12-11 21:05:24   \n",
       "5      Sports      roaringriot 2019-12-11 17:46:56   \n",
       "6      Sports      SkyFootball 2019-12-11 21:38:56   \n",
       "7      Sports              NFL 2019-12-11 23:54:36   \n",
       "8      Sports              NFL 2019-12-11 23:40:48   \n",
       "9      Sports        chiproytx 2019-12-11 21:20:16   \n",
       "10     Sports     darrenrovell 2019-12-11 22:46:49   \n",
       "11     Sports      OnionSports 2019-12-11 22:38:07   \n",
       "12     Sports         RoyNemer 2019-12-11 22:49:49   \n",
       "13     Sports         RoyNemer 2019-12-11 22:51:26   \n",
       "14     Sports     AdamHBeasley 2019-12-11 21:50:39   \n",
       "15     Sports         Ouachita 2019-12-11 17:30:11   \n",
       "16     Sports  GeoffBakerTIMES 2019-12-11 17:24:31   \n",
       "17     Sports           cmdabe 2019-12-11 17:42:07   \n",
       "18     Sports   HoustonChronHS 2019-12-11 17:40:24   \n",
       "19     Sports       rameshlaus 2019-12-11 16:58:33   \n",
       "20     Sports              NFL 2019-12-11 02:15:19   \n",
       "21     Sports         UKLabour 2019-12-11 16:30:00   \n",
       "22     Sports   ArvindKejriwal 2019-12-11 12:14:59   \n",
       "23     Sports   orangeandwhite 2019-12-11 18:51:30   \n",
       "24     Sports        UberFacts 2019-12-11 00:47:01   \n",
       "25     Sports        GetUpESPN 2019-12-11 15:08:40   \n",
       "26     Sports              NFL 2019-12-11 03:54:30   \n",
       "27     Sports              NFL 2019-12-11 03:31:54   \n",
       "28     Sports  BABYMETAL_JAPAN 2019-12-11 04:02:22   \n",
       "29     Sports              NFL 2019-12-11 00:24:17   \n",
       "..        ...              ...                 ...   \n",
       "224  Business      sekartweets 2019-12-11 14:06:12   \n",
       "225  Business       mannyfidel 2019-12-11 18:40:28   \n",
       "226  Business          nytimes 2019-12-11 15:54:34   \n",
       "227  Business        paulmozur 2019-12-11 09:03:03   \n",
       "228  Business       EpochTimes 2019-12-11 03:10:01   \n",
       "229  Business      AnandWrites 2019-12-11 22:31:57   \n",
       "230  Business          cvpayne 2019-12-11 18:49:05   \n",
       "231  Business         HawleyMO 2019-12-11 21:11:04   \n",
       "232  Business      RepJimBanks 2019-12-11 15:19:35   \n",
       "233  Business   BleacherReport 2019-12-11 04:28:55   \n",
       "234  Business           Timodc 2019-12-11 03:51:59   \n",
       "235  Business       jrhennessy 2019-12-11 22:13:35   \n",
       "236  Business         ashoswai 2019-12-11 07:21:38   \n",
       "237  Business              ABC 2019-12-11 04:54:05   \n",
       "238  Business       EpochTimes 2019-12-11 00:25:00   \n",
       "239  Business         CREWcrew 2019-12-11 00:00:46   \n",
       "240  Business              GOP 2019-12-11 00:12:00   \n",
       "241  Business      BillKristol 2019-12-11 00:57:10   \n",
       "242  Business              WWE 2019-12-11 02:19:22   \n",
       "243  Business    prasannavishy 2019-12-11 00:10:26   \n",
       "244  Business     WorldWideWob 2019-12-11 02:58:53   \n",
       "245  Business          latimes 2019-12-11 01:48:00   \n",
       "246  Business     blakeshelton 2019-12-11 00:30:00   \n",
       "247  Business       PaulBegala 2019-12-11 00:12:51   \n",
       "248  Business         business 2019-12-11 02:54:26   \n",
       "249  Business         business 2019-12-11 02:38:21   \n",
       "250  Business       jaketapper 2019-12-11 02:03:41   \n",
       "251  Business     JonErlichman 2019-12-11 00:17:13   \n",
       "252  Business   RobertMaguire_ 2019-12-11 00:56:46   \n",
       "253  Business           foe_us 2019-12-11 00:00:04   \n",
       "\n",
       "                                                  text  \\\n",
       "0    What are we doing this week to ruin sports for...   \n",
       "1    Enthusiastic \"new Swede\" proves his sporting i...   \n",
       "2    [?][?] The sports world hails Leo #Messi #Ball...   \n",
       "3    Few bad games in Cricket and everyone, from sh...   \n",
       "4    The repetitive relic that is \"Conference Champ...   \n",
       "5    We are still Panthers fans today, forever and ...   \n",
       "6    Austin converts from the spot in the 90th minu...   \n",
       "7    .@stefondiggs playing catch with fans pregame!...   \n",
       "8    Canada's own @LWillson_82 loves that look, @TD...   \n",
       "9    \"J.K. Dobbins' mom, Mya, became pregnant when ...   \n",
       "10   Four players were suspended from the NFL for s...   \n",
       "11   Dallas Cowboys Release Jerry Jones https://t.c...   \n",
       "12   Messi could have zero Ballon d'Ors and it woul...   \n",
       "13   Imagine someone dominating in goals scored, as...   \n",
       "14   A lot of people who talk and write about footb...   \n",
       "15   If you've never made it to see the Battle of t...   \n",
       "16   Under fire for handling of player abuse allega...   \n",
       "17   .@ArchRUMMEL moves up another spot in latest U...   \n",
       "18   Morton Ranch's Brown, Paetow's Mourning, Katy'...   \n",
       "19   #YahooIndia Most Searched Sports Personality o...   \n",
       "20   One of the craziest Pick-6s you'll ever see.\\r...   \n",
       "21   These 5 employers have exploited, ripped off a...   \n",
       "22   We passed Bills in Del Assembly in last 2 days...   \n",
       "23   Paul Finebaum called Dabo Swinney \"the most an...   \n",
       "24   In 1989, a couple from New York paid $100 for ...   \n",
       "25   \"I think Dabo Swinney is the most annoying win...   \n",
       "26    FAKE PUNT ALERT \\r\\n\\r\\nThe @Seahawks special...   \n",
       "27   WIDE OPEN.\\r\\n\\r\\n@DangeRussWilson to David Mo...   \n",
       "28   METAL GALAXY WORLD TOUR (TAIPEI ) - Ticket Inf...   \n",
       "29   \"Time to be great.\" - @DangeRussWilson #Seahaw...   \n",
       "..                                                 ...   \n",
       "224  #27YrsOfKwEmperorVIJAY - From facing brutal cr...   \n",
       "225  I'm willing to raise the necessary funds for K...   \n",
       "226  Breaking News: Deutsche Bank must turn over de...   \n",
       "227  In Xinjiang, Chinese police are using the bloo...   \n",
       "228  6 out of 10 small business owners approve of P...   \n",
       "229  The moral meltdown of McKinsey is one of the m...   \n",
       "230  I'm in DC were I just wrapped an exclusive int...   \n",
       "231  #China using DNA to create facial images to tr...   \n",
       "232  China using DNA samples to map Uighur faces as...   \n",
       "233  .@DangeRussWilson leads the Seahawks past the ...   \n",
       "234  So weird that America First isolationism alway...   \n",
       "235  the big consulting firms really do not suffer ...   \n",
       "236  #Kashmir is only place in the world, where reg...   \n",
       "237  China says it will suspend U.S. Navy visits to...   \n",
       "238  6 out of 10 small business owners approve of P...   \n",
       "239  Donald Trump has now made an astounding 400 pr...   \n",
       "240  Promises MADE, promises KEPT!\\r\\n\\r\\nhttps://t...   \n",
       "241  \"Trump has long maintained that he did not hav...   \n",
       "242  More business is about to be handled by @Andra...   \n",
       "243  The economics of Christian anti-Semitism - As ...   \n",
       "244  this is a tweet to inform you the Knicks score...   \n",
       "245  Column: Buttigieg is wrong--Free college shoul...   \n",
       "246  Had a blast taking care of business last week ...   \n",
       "247  In a business with too many narcissists, charl...   \n",
       "248  The U.S. is bracing for a possible French fry ...   \n",
       "249  China hints a U.S. blacklist of \"unreliable en...   \n",
       "250  LA Times: Jury orders billionaire Alki David t...   \n",
       "251  VC investments in space startups:\\r\\n \\r\\n2019...   \n",
       "252  The administration headed by a president who s...   \n",
       "253  Emails show that chemical giant @Bayer discuss...   \n",
       "\n",
       "                                                emojis  favorite_count  \\\n",
       "0                              SMILING FACE WITH HORNS           68595   \n",
       "1                                                  NaN             916   \n",
       "2                                                  NaN           14383   \n",
       "3                                                  NaN            2087   \n",
       "4                                                  NaN            1129   \n",
       "5                                                  NaN             295   \n",
       "6                                                  NaN             970   \n",
       "7            AMERICAN FOOTBALL,TELEVISION,MOBILE PHONE             705   \n",
       "8    FACE WITH TEARS OF JOY,REGIONAL INDICATOR SYMB...             668   \n",
       "9                                                  NaN             225   \n",
       "10                                                 NaN             170   \n",
       "11                                                 NaN             423   \n",
       "12                                                 NaN             486   \n",
       "13                                                 NaN             381   \n",
       "14                                                 NaN             609   \n",
       "15                                                 NaN             118   \n",
       "16                                                 NaN              48   \n",
       "17                                                 NaN              54   \n",
       "18                                                 NaN              55   \n",
       "19                                                 NaN           11747   \n",
       "20   HOUSE BUILDING,COMBINING ENCLOSING KEYCAP,TELE...            2281   \n",
       "21   PERSONAL COMPUTER,T-SHIRT,HOSPITAL,SHOPPING BA...            1292   \n",
       "22                                                 NaN            9462   \n",
       "23                                                 NaN            2061   \n",
       "24                                                 NaN            3988   \n",
       "25              FLUSHED FACE,FLUSHED FACE,FLUSHED FACE            6109   \n",
       "26   POLICE CARS REVOLVING LIGHT,POLICE CARS REVOLV...            2567   \n",
       "27                                          TELEVISION            1870   \n",
       "28                                                 NaN            2515   \n",
       "29                             TELEVISION,MOBILE PHONE            3347   \n",
       "..                                                 ...             ...   \n",
       "224                                                NaN            5205   \n",
       "225                                                NaN           14091   \n",
       "226                                                NaN            9317   \n",
       "227                                                NaN            5621   \n",
       "228                                                NaN             760   \n",
       "229                                                NaN            1895   \n",
       "230                                                NaN            6144   \n",
       "231                                                NaN            3233   \n",
       "232                                                NaN            3288   \n",
       "233                                                NaN            6581   \n",
       "234                                                NaN            2433   \n",
       "235                                                NaN            1797   \n",
       "236                                                NaN             727   \n",
       "237                                                NaN            2345   \n",
       "238                                                NaN            1001   \n",
       "239                                                NaN             241   \n",
       "240                                                NaN            4692   \n",
       "241                                                NaN             452   \n",
       "242                                                NaN            1068   \n",
       "243                                                NaN             111   \n",
       "244                                                NaN             812   \n",
       "245                                                NaN             604   \n",
       "246                                                NaN            1980   \n",
       "247                                                NaN             423   \n",
       "248                                                NaN             135   \n",
       "249                                                NaN              51   \n",
       "250                                                NaN             436   \n",
       "251                                                NaN             337   \n",
       "252                                                NaN             136   \n",
       "253                                                NaN              22   \n",
       "\n",
       "     retweet_count  follower_count  popularity  \n",
       "0            15994           30470    2.776140  \n",
       "1              642          129758    0.012007  \n",
       "2             2244        31410733    0.000529  \n",
       "3              342          181730    0.013366  \n",
       "4              210          291320    0.004596  \n",
       "5              228           18932    0.027625  \n",
       "6              114          352007    0.003079  \n",
       "7               81        24818782    0.000032  \n",
       "8               85        24818782    0.000030  \n",
       "9               95           22615    0.014150  \n",
       "10              51         2053828    0.000108  \n",
       "11              93          268621    0.001921  \n",
       "12             100           21724    0.026975  \n",
       "13              92           21724    0.021773  \n",
       "14              95           45673    0.015414  \n",
       "15              47            7648    0.021574  \n",
       "16              28           25398    0.002992  \n",
       "17              17            2918    0.024332  \n",
       "18              15           14348    0.004879  \n",
       "19            2568          433079    0.033054  \n",
       "20             585        24818781    0.000115  \n",
       "21             703          792238    0.002518  \n",
       "22            1745        15957107    0.000702  \n",
       "23             310           39845    0.059506  \n",
       "24             363        13979016    0.000311  \n",
       "25            1198           73069    0.100001  \n",
       "26             490        24818781    0.000123  \n",
       "27             444        24818781    0.000093  \n",
       "28             495          350224    0.008594  \n",
       "29             436        24818781    0.000152  \n",
       "..             ...             ...         ...  \n",
       "224           2624          122778    0.063765  \n",
       "225           1890            8464    1.888114  \n",
       "226           3913        44614211    0.000297  \n",
       "227           5344           31485    0.348261  \n",
       "228            585          165213    0.008141  \n",
       "229            820          563991    0.004814  \n",
       "230           1487          415198    0.018379  \n",
       "231           2389          132243    0.042513  \n",
       "232           3189           21642    0.299279  \n",
       "233            889         7787569    0.000959  \n",
       "234            593           91111    0.033212  \n",
       "235            566           28296    0.083510  \n",
       "236            497          143069    0.008555  \n",
       "237           2205        14717857    0.000309  \n",
       "238            412          165213    0.008553  \n",
       "239            182          303543    0.001394  \n",
       "240           1409         2129572    0.002865  \n",
       "241            222          560365    0.001203  \n",
       "242            244        10754452    0.000122  \n",
       "243             80          103026    0.001854  \n",
       "244             64          468145    0.001871  \n",
       "245            181         3464266    0.000227  \n",
       "246            141        20587052    0.000103  \n",
       "247             57          207339    0.002315  \n",
       "248             75         5739652    0.000037  \n",
       "249             52         5739652    0.000018  \n",
       "250            131         2203713    0.000257  \n",
       "251            120          113548    0.004025  \n",
       "252             88           60249    0.003718  \n",
       "253             22          169687    0.000259  \n",
       "\n",
       "[254 rows x 9 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-11 18:30:00', freq='30T')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_max_time_category(category):\n",
    "    groups = data.groupby(['category'])\n",
    "    category = groups.get_group(category)\n",
    "    time_grpr = category.groupby(pd.Grouper(key='created_at', freq='30min'))\n",
    "    count_grpr = time_grpr['text'].count()\n",
    "    sum_grpr = time_grpr['popularity'].sum()\n",
    "    popularity = sum_grpr/count_grpr\n",
    "    popularity = (popularity - popularity.min()) / (popularity.max() - popularity.min()) \n",
    "    popularity = popularity.fillna(0)\n",
    "    popularity = popularity.rename('popularity')\n",
    "    popularity_df = popularity.to_frame()\n",
    "    popularity_df['tmpstmp'] = popularity.index\n",
    "    popularity_df['tmpstmp'] = popularity_df['tmpstmp'].dt.time.astype(str)\n",
    "    plt.bar(popularity_df['tmpstmp'],height = popularity_df['popularity'])\n",
    "    max_time = popularity_df['popularity'].idxmax()\n",
    "    return max_time\n",
    "\n",
    "get_max_time_category('Politics')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = \"jKh08dfgDeTPztN1rzCpTG7Ub\"\n",
    "consumer_secret = \"piCHq08QogdkccQjQ4w74ejfNZl0ZLJeN5QDfkyNKp1AUG1nL8\"\n",
    "access_token = \"968209315285946373-kB1go0AZDLjgR3uw8D04fkekvLNGrM2\"\n",
    "access_secret = \"49zXLZmjYPdVwIufciUGgM5vtn9YtLD4YehU6pydKCWZY\"\n",
    "print(\"hello\")\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "user = api.get_user(user_name)\n",
    "follower_count = user.followers_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>emojis</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-11 15:01:00</td>\n",
       "      <td>#Saints DE Marcus Davenport suffered a signifi...</td>\n",
       "      <td></td>\n",
       "      <td>329.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.323373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-12-11 15:00:00</td>\n",
       "      <td>All the best touchdowns from an AMAZING Week 1...</td>\n",
       "      <td></td>\n",
       "      <td>342.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.267596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-11 14:26:00</td>\n",
       "      <td>RT to cast a #ProBowlVote for our Bucks\\n@Cant...</td>\n",
       "      <td></td>\n",
       "      <td>760.0</td>\n",
       "      <td>746.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-12-11 14:30:00</td>\n",
       "      <td>These five rookies balled out in Week 14!  (vi...</td>\n",
       "      <td></td>\n",
       "      <td>320.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.238380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-12-11 14:00:00</td>\n",
       "      <td>Source: #Redskins RB Derrius Guice is going on...</td>\n",
       "      <td></td>\n",
       "      <td>973.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>0.778220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019-12-11 14:00:00</td>\n",
       "      <td>The @Vikings defense was DOMINANT in Week 14. ...</td>\n",
       "      <td></td>\n",
       "      <td>303.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.229748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019-12-11 18:00:00</td>\n",
       "      <td>The Walmart in Fort Pierce, Fla., revealed Bea...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019-12-11 12:47:00</td>\n",
       "      <td>Time to support your Tigers in the @NFL \\n RT...</td>\n",
       "      <td></td>\n",
       "      <td>467.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>0.542497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019-12-11 13:05:00</td>\n",
       "      <td>Eagles WR Alshon Jeffery (foot) to miss rest o...</td>\n",
       "      <td></td>\n",
       "      <td>940.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0.765604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019-12-11 13:00:00</td>\n",
       "      <td>2019 Passing Yards Leaders through Week 14! \\n...</td>\n",
       "      <td></td>\n",
       "      <td>794.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.615538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019-12-11 12:45:00</td>\n",
       "      <td>Lamar Jackson (quad) on the field at #Ravens w...</td>\n",
       "      <td></td>\n",
       "      <td>253.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.194555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-12-11 12:39:00</td>\n",
       "      <td>The 15 HIGHEST-GRADED players from Week 14!  (...</td>\n",
       "      <td></td>\n",
       "      <td>477.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.367862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-12-11 12:12:00</td>\n",
       "      <td>1 RT = 1 Vote \\n\\nRT TO VOTE &amp; TO SUPPORT YOUR...</td>\n",
       "      <td></td>\n",
       "      <td>393.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>0.596282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-12-11 12:05:00</td>\n",
       "      <td>This Week in #NFL100 : Week 15\\nhttps://bit.ly...</td>\n",
       "      <td></td>\n",
       "      <td>54.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.045153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-12-11 12:09:00</td>\n",
       "      <td>He really made two defenders hug each other......</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-12-11 12:00:00</td>\n",
       "      <td>The postseason is three weeks away.\\n\\nIs YOUR...</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>0.231740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-12-11 11:00:00</td>\n",
       "      <td>Congrats on making it this far.\\n\\nNow grab on...</td>\n",
       "      <td></td>\n",
       "      <td>197.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.142098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-12-11 09:32:00</td>\n",
       "      <td>1 RT = 1 vote\\n\\n#ProBowlVote + @dak\\n#ProBowl...</td>\n",
       "      <td></td>\n",
       "      <td>487.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.841965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-12-11 10:00:00</td>\n",
       "      <td>.@Showtyme_33 had another HUGE game in Week 14...</td>\n",
       "      <td></td>\n",
       "      <td>886.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.656707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-12-11 09:50:00</td>\n",
       "      <td>\"You know how much composure it takes to make ...</td>\n",
       "      <td></td>\n",
       "      <td>914.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.691235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2019-12-11 15:01:00  #Saints DE Marcus Davenport suffered a signifi...   \n",
       "1  2019-12-11 15:00:00  All the best touchdowns from an AMAZING Week 1...   \n",
       "2  2019-12-11 14:26:00  RT to cast a #ProBowlVote for our Bucks\\n@Cant...   \n",
       "3  2019-12-11 14:30:00  These five rookies balled out in Week 14!  (vi...   \n",
       "4  2019-12-11 14:00:00  Source: #Redskins RB Derrius Guice is going on...   \n",
       "5  2019-12-11 14:00:00  The @Vikings defense was DOMINANT in Week 14. ...   \n",
       "6  2019-12-11 18:00:00  The Walmart in Fort Pierce, Fla., revealed Bea...   \n",
       "7  2019-12-11 12:47:00   Time to support your Tigers in the @NFL \\n RT...   \n",
       "8  2019-12-11 13:05:00  Eagles WR Alshon Jeffery (foot) to miss rest o...   \n",
       "9  2019-12-11 13:00:00  2019 Passing Yards Leaders through Week 14! \\n...   \n",
       "10 2019-12-11 12:45:00  Lamar Jackson (quad) on the field at #Ravens w...   \n",
       "11 2019-12-11 12:39:00  The 15 HIGHEST-GRADED players from Week 14!  (...   \n",
       "12 2019-12-11 12:12:00  1 RT = 1 Vote \\n\\nRT TO VOTE & TO SUPPORT YOUR...   \n",
       "13 2019-12-11 12:05:00  This Week in #NFL100 : Week 15\\nhttps://bit.ly...   \n",
       "14 2019-12-11 12:09:00  He really made two defenders hug each other......   \n",
       "15 2019-12-11 12:00:00  The postseason is three weeks away.\\n\\nIs YOUR...   \n",
       "16 2019-12-11 11:00:00  Congrats on making it this far.\\n\\nNow grab on...   \n",
       "17 2019-12-11 09:32:00  1 RT = 1 vote\\n\\n#ProBowlVote + @dak\\n#ProBowl...   \n",
       "18 2019-12-11 10:00:00  .@Showtyme_33 had another HUGE game in Week 14...   \n",
       "19 2019-12-11 09:50:00  \"You know how much composure it takes to make ...   \n",
       "\n",
       "   emojis  favorite_count  retweet_count  popularity  \n",
       "0                   329.0          158.0    0.323373  \n",
       "1                   342.0           61.0    0.267596  \n",
       "2                   760.0          746.0    1.000000  \n",
       "3                   320.0           39.0    0.238380  \n",
       "4                   973.0          199.0    0.778220  \n",
       "5                   303.0           43.0    0.229748  \n",
       "6                     0.0            0.0    0.000000  \n",
       "7                   467.0          350.0    0.542497  \n",
       "8                   940.0          213.0    0.765604  \n",
       "9                   794.0          133.0    0.615538  \n",
       "10                  253.0           40.0    0.194555  \n",
       "11                  477.0           77.0    0.367862  \n",
       "12                  393.0          505.0    0.596282  \n",
       "13                   54.0           14.0    0.045153  \n",
       "14                    0.0            0.0    0.000000  \n",
       "15                    0.0          349.0    0.231740  \n",
       "16                  197.0           17.0    0.142098  \n",
       "17                  487.0          781.0    0.841965  \n",
       "18                  886.0          103.0    0.656707  \n",
       "19                  914.0          127.0    0.691235  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_timeline_df['created_at'] = user_timeline_df['created_at'].astype(str)\n",
    "user_timeline_df['created_at'] = pd.DatetimeIndex(user_timeline_df['created_at'])\n",
    "user_timeline_df['created_at'] = user_timeline_df['created_at'].dt.time.astype(str)\n",
    "user_timeline_df['created_at'] = pd.DatetimeIndex(user_timeline_df['created_at'])\n",
    "user_timeline_df['popularity'] = (user_timeline_df['favorite_count'] + user_timeline_df['retweet_count'])/follower_count\n",
    "user_timeline_df['popularity'] = (user_timeline_df['popularity'] - user_timeline_df['popularity'].min()) / (user_timeline_df['popularity'].max() - user_timeline_df['popularity'].min())\n",
    "user_timeline_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     popularity             tmpstmp\n",
      "created_at                                         \n",
      "2019-12-10 09:30:00    0.841965 2019-12-10 09:30:00\n",
      "2019-12-10 09:40:00    0.000000 2019-12-10 09:40:00\n",
      "2019-12-10 09:50:00    0.691235 2019-12-10 09:50:00\n",
      "2019-12-10 10:00:00    0.656707 2019-12-10 10:00:00\n",
      "2019-12-10 10:10:00    0.000000 2019-12-10 10:10:00\n",
      "2019-12-10 10:20:00    0.000000 2019-12-10 10:20:00\n",
      "2019-12-10 10:30:00    0.000000 2019-12-10 10:30:00\n",
      "2019-12-10 10:40:00    0.000000 2019-12-10 10:40:00\n",
      "2019-12-10 10:50:00    0.000000 2019-12-10 10:50:00\n",
      "2019-12-10 11:00:00    0.142098 2019-12-10 11:00:00\n",
      "2019-12-10 11:10:00    0.000000 2019-12-10 11:10:00\n",
      "2019-12-10 11:20:00    0.000000 2019-12-10 11:20:00\n",
      "2019-12-10 11:30:00    0.000000 2019-12-10 11:30:00\n",
      "2019-12-10 11:40:00    0.000000 2019-12-10 11:40:00\n",
      "2019-12-10 11:50:00    0.000000 2019-12-10 11:50:00\n",
      "2019-12-10 12:00:00    0.092297 2019-12-10 12:00:00\n",
      "2019-12-10 12:10:00    0.596282 2019-12-10 12:10:00\n",
      "2019-12-10 12:20:00    0.000000 2019-12-10 12:20:00\n",
      "2019-12-10 12:30:00    0.367862 2019-12-10 12:30:00\n",
      "2019-12-10 12:40:00    0.368526 2019-12-10 12:40:00\n",
      "2019-12-10 12:50:00    0.000000 2019-12-10 12:50:00\n",
      "2019-12-10 13:00:00    0.690571 2019-12-10 13:00:00\n",
      "2019-12-10 13:10:00    0.000000 2019-12-10 13:10:00\n",
      "2019-12-10 13:20:00    0.000000 2019-12-10 13:20:00\n",
      "2019-12-10 13:30:00    0.000000 2019-12-10 13:30:00\n",
      "2019-12-10 13:40:00    0.000000 2019-12-10 13:40:00\n",
      "2019-12-10 13:50:00    0.000000 2019-12-10 13:50:00\n",
      "2019-12-10 14:00:00    0.503984 2019-12-10 14:00:00\n",
      "2019-12-10 14:10:00    0.000000 2019-12-10 14:10:00\n",
      "2019-12-10 14:20:00    1.000000 2019-12-10 14:20:00\n",
      "2019-12-10 14:30:00    0.238380 2019-12-10 14:30:00\n",
      "2019-12-10 14:40:00    0.000000 2019-12-10 14:40:00\n",
      "2019-12-10 14:50:00    0.000000 2019-12-10 14:50:00\n",
      "2019-12-10 15:00:00    0.295485 2019-12-10 15:00:00\n",
      "2019-12-10 15:10:00    0.000000 2019-12-10 15:10:00\n",
      "2019-12-10 15:20:00    0.000000 2019-12-10 15:20:00\n",
      "2019-12-10 15:30:00    0.000000 2019-12-10 15:30:00\n",
      "2019-12-10 15:40:00    0.000000 2019-12-10 15:40:00\n",
      "2019-12-10 15:50:00    0.000000 2019-12-10 15:50:00\n",
      "2019-12-10 16:00:00    0.000000 2019-12-10 16:00:00\n",
      "2019-12-10 16:10:00    0.000000 2019-12-10 16:10:00\n",
      "2019-12-10 16:20:00    0.000000 2019-12-10 16:20:00\n",
      "2019-12-10 16:30:00    0.000000 2019-12-10 16:30:00\n",
      "2019-12-10 16:40:00    0.000000 2019-12-10 16:40:00\n",
      "2019-12-10 16:50:00    0.000000 2019-12-10 16:50:00\n",
      "2019-12-10 17:00:00    0.000000 2019-12-10 17:00:00\n",
      "2019-12-10 17:10:00    0.000000 2019-12-10 17:10:00\n",
      "2019-12-10 17:20:00    0.000000 2019-12-10 17:20:00\n",
      "2019-12-10 17:30:00    0.000000 2019-12-10 17:30:00\n",
      "2019-12-10 17:40:00    0.000000 2019-12-10 17:40:00\n",
      "2019-12-10 17:50:00    0.000000 2019-12-10 17:50:00\n",
      "2019-12-10 18:00:00    0.000000 2019-12-10 18:00:00\n"
     ]
    }
   ],
   "source": [
    "def get_max_time_user():\n",
    "    user_time_grpr = user_timeline_df.groupby(pd.Grouper(key='created_at', freq='10min'))\n",
    "    user_count_grpr = user_time_grpr['text'].count()\n",
    "    user_sum_grpr = user_time_grpr['popularity'].sum()\n",
    "    user_popularity = user_sum_grpr/user_count_grpr\n",
    "    user_popularity = user_popularity.fillna(0)\n",
    "    user_popularity = user_popularity.rename('popularity')\n",
    "    user_popularity_df = user_popularity.to_frame()\n",
    "    user_popularity_df['tmpstmp'] = user_popularity.index\n",
    "    user_popularity_df['tmpstmp'] = user_popularity_df['tmpstmp'].dt.time.astype(str)\n",
    "    plt.bar(user_popularity_df['tmpstmp'],height = user_popularity_df['popularity'])\n",
    "    user_max_time = user_popularity_df['popularity'].idxmax()\n",
    "    return user_max_time\n",
    "\n",
    "user_max_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.4083333333333334, subjectivity=0.5333333333333333)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fetch_sentiment_using_textblob(text):\n",
    "    analysis = TextBlob(text)\n",
    "    print(analysis.sentiment)\n",
    "    if analysis.sentiment.polarity >= 0:\n",
    "        return 'positive'\n",
    "    else:\n",
    "        return 'negative'\n",
    "    \n",
    "fetch_sentiment_using_textblob(orig_tweet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
